import requests
import urllib3
from llama_index.core import VectorStoreIndex, Document, StorageContext, load_index_from_storage
from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import os

# ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø§Ø®Ø·Ø§Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ SSL (Ú†ÙˆÙ† IP Ù…Ø³ØªÙ‚ÛŒÙ… Ù…ÛŒØ²Ù†ÛŒ)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ---------------------------------------------------------
# 1. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„
# ---------------------------------------------------------
Settings.llm = Ollama(model="qwen2:1.5b", request_timeout=120.0)
Settings.embed_model = HuggingFaceEmbedding(model_name="intfloat/multilingual-e5-large")

# ---------------------------------------------------------
# 2. ØªÙ†Ø¸ÛŒÙ…Ø§Øª API
# ---------------------------------------------------------
API_BASE_URL = "https://185.204.170.142/api/v1"
# ØªÙˆÚ©Ù† Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡ (Ø§Ú¯Ø± Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ø¬Ø¯ÛŒØ¯ Ø¨Ú¯ÛŒØ±ÛŒ)
AUTH_TOKEN = "1735%7CCfDJ8AHj4VWfmz9DpMpNxts7109iJyV5YLZVw3PwbvKW5DKqAEgJJH9q%2FbrwZH5%2Bea87uMdj4LXj58uTZ7snP8YcRP36uezVDspGvzUhEQTQ5Du4icTip2mah0Cq4C86s%2Bpy31PAxl%2FpsRIJXlugy7EmHgSgq9sOgSW9YPr%2BB1Pf2gdT4umedbopK1a0%2F6YKPrBL2Q9%2BNM2XzeBSmFcgXEvsT5rP28t%2BUIC2veZU99lS2849"
HEADERS = {"Authorization": f"Bearer {AUTH_TOKEN}"}

def fetch_all_pages(endpoint, item_processor_func, batch_size=100):
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙ…Ø§Ù… ØµÙØ­Ø§Øª API Ø±Ø§ ÙˆØ±Ù‚ Ù…ÛŒâ€ŒØ²Ù†Ø¯ Ùˆ Ø¯ÛŒØªØ§Ù‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
    """
    documents = []
    skip = 0
    total_fetched = 0
    
    print(f"ðŸ“¥ Start fetching from: {endpoint}...")
    
    while True:
        params = {
            "PagingDto.PageFilter.Size": batch_size,
            "PagingDto.PageFilter.Skip": skip,
            "PagingDto.PageFilter.ReturnTotalRecordsCount": "true"
        }
        
        try:
            response = requests.get(
                f"{API_BASE_URL}/{endpoint}", 
                params=params, 
                headers=HEADERS, 
                verify=False, 
                timeout=30
            )
            
            if response.status_code != 200:
                print(f"âš ï¸ Error {response.status_code} in {endpoint}")
                break
                
            data = response.json()
            # Ø·Ø¨Ù‚ Ù…Ø³ØªÙ†Ø¯Ø§ØªØŒ Ø¯ÛŒØªØ§ Ù…Ø¹Ù…ÙˆÙ„Ø§ Ø¯Ø± data.list ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø´Ø§Ø¨Ù‡ Ø§Ø³Øª
            # Ø§ÛŒÙ†Ø¬Ø§ ÙØ±Ø¶ Ø±Ø§ Ø¨Ø± Ø³Ø§Ø®ØªØ§Ø± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ data['data']['list'] Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ…
            # Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø³ÙˆØ§Ú¯Ø±ØŒ Ø¨Ø±Ø®ÛŒ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¢Ø±Ø§ÛŒÙ‡ Ù‡Ø³ØªÙ†Ø¯ ÛŒØ§ Ø¯Ø§Ø®Ù„ data
            
            items = []
            if "data" in data and isinstance(data["data"], dict) and "list" in data["data"]:
                items = data["data"]["list"]
            elif "data" in data and isinstance(data["data"], list):
                items = data["data"]
            
            if not items:
                break  # Ù¾Ø§ÛŒØ§Ù† Ø¯ÛŒØªØ§
                
            for item in items:
                doc = item_processor_func(item)
                if doc:
                    documents.append(doc)
            
            fetched_count = len(items)
            total_fetched += fetched_count
            skip += fetched_count
            
            print(f"   -> Fetched {fetched_count} items (Total: {total_fetched})")
            
            if fetched_count < batch_size:
                break # ØµÙØ­Ù‡ Ø¢Ø®Ø±
                
        except Exception as e:
            print(f"âŒ Exception fetching {endpoint}: {e}")
            break
            
    return documents

# --- ØªÙˆØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ù†ÙˆØ¹ Ø¯ÛŒØªØ§ ---

def process_blog(item):
    # ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒØªØ§ÛŒ Ø¨Ù„Ø§Ú¯ Ø¨Ù‡ Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
    title = item.get("title", "")
    summary = item.get("summary", "")
    # Ø§Ú¯Ø± Ù…ØªÙ† Ú©Ø§Ù…Ù„ (Body) Ø¯Ø± Ù„ÛŒØ³Øª Ù†ÛŒØ³ØªØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ Ø¨Ø§ ID Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø²Ù†ÛŒ
    # Ø§Ù…Ø§ ÙØ¹Ù„Ø§ Title Ùˆ Summary Ø±Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    text = f"Title: {title}\nSummary: {summary}"
    return Document(text=text, metadata={"type": "blog", "id": item.get("id")})

def process_school(item):
    name = item.get("name", "")
    if "gamatrain" in name.lower(): return None # Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªØ³ØªÛŒ
    
    city = item.get("cityTitle", "")
    desc = item.get("description", "") or "No description"
    text = f"School Name: {name}\nCity: {city}\nDescription: {desc}"
    return Document(text=text, metadata={"type": "school", "id": item.get("id")})

def process_question(item):
    # ÙØ±Ø¶ Ø¨Ø± Ø³Ø§Ø®ØªØ§Ø± Ø³ÙˆØ§Ù„ Ø¯Ø± API
    q_text = item.get("questionText", "") or item.get("title", "")
    if not q_text: return None
    text = f"Question Sample: {q_text}"
    return Document(text=text, metadata={"type": "question", "id": item.get("id")})

def process_subject(item):
    title = item.get("title", "")
    text = f"Educational Subject: {title}"
    return Document(text=text, metadata={"type": "subject", "id": item.get("id")})

def build_index():
    all_docs = []
    
    # 1. Ø¯Ø±ÛŒØ§ÙØª Ø¨Ù„Ø§Ú¯â€ŒÙ‡Ø§
    all_docs.extend(fetch_all_pages("blogs/posts", process_blog))
    
    # 2. Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¯Ø§Ø±Ø³
    all_docs.extend(fetch_all_pages("schools", process_school))
    
    # 3. Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„Ø§Øª (Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø³ÙˆØ§Ù„ Ø­Ù„ Ú©Ù†Ø¯)
    all_docs.extend(fetch_all_pages("questions", process_question))

    # 4. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±ÙˆØ³
    all_docs.extend(fetch_all_pages("subjects", process_subject))

    if not all_docs:
        print("âš ï¸ No data fetched! Check your TOKEN or API Access.")
        return None

    print(f"ðŸš€ Total Documents to Index: {len(all_docs)}")
    
    # Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³
    if not os.path.exists("./storage"):
        index = VectorStoreIndex.from_documents(all_docs)
        index.storage_context.persist()
    else:
        ctx = StorageContext.from_defaults(persist_dir="./storage")
        index = load_index_from_storage(ctx)
        
    return index

def main():
    index = build_index()
    if not index: return
    
    query_engine = index.as_query_engine()
    
    print("\nâœ… System Ready! Ask your question:")
    while True:
        q = input("> ")
        if q in ["exit", "quit"]: break
        print(query_engine.query(q))

if __name__ == "__main__":
    main()
